{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slax_full():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    import slax as sl\n",
    "    import flax.linen as nn\n",
    "\n",
    "    key = jax.random.PRNGKey(0)\n",
    "\n",
    "    benchmark_title = f\"slax full-precision v{'0.0.1'}\"\n",
    "\n",
    "    def prepare_fn(batch_size, n_steps, n_neurons, n_layers, device):\n",
    "        class Model(nn.Module):\n",
    "            @nn.compact\n",
    "            def __call__(self,x):\n",
    "                x = nn.Dense(n_neurons)(x)\n",
    "                x = sl.RNN(sl.LIF(2.,spike_fn=sl.atan()))(x)\n",
    "                x = nn.Dense(n_neurons)(x)\n",
    "                x = sl.RNN(sl.LIF(2.,spike_fn=sl.atan()))(x)\n",
    "                x = nn.Dense(n_neurons)(x)\n",
    "                x = sl.RNN(sl.LIF(2.,spike_fn=sl.atan()))(x)\n",
    "\n",
    "                return x\n",
    "\n",
    "        input_static = jax.random.normal(key,shape=(n_steps, batch_size, n_neurons), dtype=jnp.float32)\n",
    "\n",
    "        # Since there's nothing stochastic about the network, we can avoid using an RNG as a param!\n",
    "        SNN = Model()\n",
    "        params = SNN.init(key, input_static)\n",
    "\n",
    "\n",
    "        @jax.jit\n",
    "        def net_eval(weights, events):\n",
    "            readout = SNN.apply(weights, events,mutable=['carry'])\n",
    "            traces, V_f = readout\n",
    "            return traces.sum()\n",
    "            #return readout[0].sum()\n",
    "\n",
    "        model = (net_eval, params)\n",
    "\n",
    "        return dict(model=model, input=input_static, n_neurons=n_neurons)\n",
    "    #@jax.tree_util.Partial(jax.jit,static_argnums=(0,))\n",
    "    def forward_fn(bench_dict):\n",
    "        model, input_static = bench_dict[\"model\"], bench_dict[\"input\"]\n",
    "        net_eval, params = model\n",
    "        net_eval(params, input_static)\n",
    "        bench_dict[\"output\"] = input_static\n",
    "        return bench_dict\n",
    "\n",
    "\n",
    "    def backward_fn(bench_dict):\n",
    "        input_static = bench_dict[\"input\"]\n",
    "        net_eval, params = bench_dict[\"model\"]\n",
    "        jax.grad(net_eval)(params, input_static)\n",
    "\n",
    "    d= prepare_fn(64,500,1024,3,3)\n",
    "    backward_fn(d)\n",
    "    forward_fn(d)\n",
    "\n",
    "    return prepare_fn, forward_fn, backward_fn, benchmark_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fn, forward_fn, backward_fn, b = slax_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= prepare_fn(64,500,1024,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_fn(d);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_fn(d);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
