{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slax as sl\n",
    "import os\n",
    "#os.environ[\"ENABLE_PJRT_COMPATIBILITY\"] = \"1\"\n",
    "#import flax.linen as nn\n",
    "from flax import nnx\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import optax\n",
    "import pickle\n",
    "from jax.tree_util import tree_map, Partial, tree_leaves, tree_structure, tree_unflatten\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/Users/thomas/Downloads/spyx_xla_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.9083370685577394)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz = 64\n",
    "output_sz = 10\n",
    "seq_len = 50\n",
    "manifold_key = jax.random.PRNGKey(0)\n",
    "random_seed = manifold_key\n",
    "key = manifold_key\n",
    "batch_sz = 32\n",
    "dtype = jnp.float32\n",
    "n_steps = 5000\n",
    "nnx_key = nnx.Rngs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import flax.linen as nn\n",
    "# from flax import nnx\n",
    "# from typing import Any, Sequence\n",
    "# from jax.tree_util import Partial, tree_leaves, tree_map\n",
    "# from jax.lax import stop_gradient as stop_grad\n",
    "# from jax.flatten_util import ravel_pytree\n",
    "# from slax.models.utils import reinit_model, connect, RNN\n",
    "# from slax.train.helpers import output, sum_output, diag, rtrl_update\n",
    "# from functools import partial\n",
    "\n",
    "# def diag_rtrl_update(a,b,c):\n",
    "#     def custom_mul(x,y):\n",
    "#         if len(y.shape) == 3:\n",
    "#             return jnp.einsum('...ibj,bij->b...j',x,y)\n",
    "#         else:\n",
    "#             print(x.shape)\n",
    "#             print(y.shape)\n",
    "#             return jnp.einsum('...jbi,bjki->b...ki',x,y)\n",
    "#     return jax.tree.map(lambda x,y: custom_mul(a,x)+y,b,c)\n",
    "\n",
    "\n",
    "# class diag_rtrl(nnx.Module):\n",
    "#     def __init__(self, mdl, batch_sz, diagonal_sum=True):\n",
    "#         self.mdl = mdl\n",
    "#         graph,param,state = nnx.split(mdl,nnx.Param,...)\n",
    "#         E = [jax.tree.map(jnp.zeros_like,param)]*len(jax.tree.leaves(state))\n",
    "#         self.E = nnx.Variable(jax.tree.map(lambda *args: jnp.stack(batch_sz*[jnp.stack(args)]),*E))\n",
    "#         self.diagonal_sum = diagonal_sum\n",
    "#     @nnx.jit\n",
    "#     def __call__(self,x):\n",
    "#         @jax.custom_vjp\n",
    "#         def exec_model(graph,param,state,E,x):\n",
    "#             model = nnx.merge(graph,param,state)\n",
    "#             out = model(x)\n",
    "#             return out, nnx.split(model,nnx.Param,...)[2], E\n",
    "        \n",
    "#         def exec(graph,param,state,E,x):\n",
    "#             if self.diagonal_sum:\n",
    "#                 ((ds_dp,ds_du),(du_dp,du_du)),(out,state,f_vjp) = jax.jacrev(sum_output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "#             else:\n",
    "#                 grads,(out,state,f_vjp) = jax.jacrev(output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "#                 (ds_grad),(du_dp,du_du) = jax.tree.map(diag,grads)\n",
    "#                 ds_dp,ds_du = jax.tree.map(lambda x: x[0],ds_grad)\n",
    "            \n",
    "#             ds_du, du_du = jnp.stack(jax.tree.leaves(ds_du)), jnp.stack(jax.tree.leaves(du_du))\n",
    "#             #print(du_du)\n",
    "        \n",
    "#             ds_dtheta = diag_rtrl_update(ds_du,E,ds_dp)\n",
    "\n",
    "#             print(ds_dtheta)\n",
    "#             E = diag_rtrl_update(du_du,E,du_dp)\n",
    "#             #print(E)\n",
    "\n",
    "#             return (out,state,E), (ds_dtheta,f_vjp)\n",
    "\n",
    "#         def exec_bwd(res,g):\n",
    "#             ds_dtheta,f_vjp = res\n",
    "#             grad = jax.tree.map(lambda x: jnp.einsum('bj,b...j->...j',g[0],x),ds_dtheta)\n",
    "#             passback = jax.tree.leaves(f_vjp(g[0]))[0]\n",
    "#             #print(grad)\n",
    "#             return (None,grad,None,None,passback)\n",
    "\n",
    "#         exec_model.defvjp(exec, exec_bwd)\n",
    "#         graph, param, state = nnx.split(self.mdl,nnx.Param,...)\n",
    "#         #vp_exec = partial(jax.vmap(partial(exec_model,graph,param)),state,self.E.value)\n",
    "#         if len(x.shape)<2:\n",
    "#             x = x.reshape(1,-1)\n",
    "#         #out,state,E = vp_exec(x)\n",
    "#         out,state,E = exec_model(graph,param,state,self.E.value,x)\n",
    "#         self.E.value = E\n",
    "#         nnx.update(self.mdl,state)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "from flax import nnx\n",
    "from typing import Any, Sequence\n",
    "from jax.tree_util import Partial, tree_leaves, tree_map\n",
    "from jax.lax import stop_gradient as stop_grad\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from slax.models.utils import reinit_model, connect, RNN\n",
    "from slax.train.helpers import output, sum_output, diag, rtrl_update, diag_rtrl_update\n",
    "from functools import partial\n",
    "\n",
    "class diag_rtrl(nnx.Module):\n",
    "    def __init__(self, mdl, batch_sz, diagonal_sum=True):\n",
    "        self.mdl = mdl\n",
    "        graph,param,state = nnx.split(mdl,nnx.Param,...)\n",
    "        E = [jax.tree.map(jnp.zeros_like,param)]*len(jax.tree.leaves(state))\n",
    "        self.E = nnx.Variable(jax.tree.map(lambda *args: jnp.stack(batch_sz*[jnp.stack(args)]),*E))\n",
    "        self.diagonal_sum = diagonal_sum\n",
    "    @nnx.jit\n",
    "    def __call__(self,x):\n",
    "        @jax.custom_vjp\n",
    "        def exec_model(graph,param,state,E,x):\n",
    "            model = nnx.merge(graph,param,state)\n",
    "            out = model(x)\n",
    "            return out, nnx.split(model,nnx.Param,...)[2], E\n",
    "        \n",
    "        def exec(graph,param,state,E,x):\n",
    "            if self.diagonal_sum:\n",
    "                ((ds_dp,ds_du),(du_dp,du_du)),(out,state,f_vjp) = jax.jacrev(sum_output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "            else:\n",
    "                grads,(out,state,f_vjp) = jax.jacrev(output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "                (ds_grad),(du_dp,du_du) = jax.tree.map(diag,grads)\n",
    "                ds_dp,ds_du = jax.tree.map(lambda x: x[0],ds_grad)\n",
    "            \n",
    "            ds_du, du_du = jnp.stack(jax.tree.leaves(ds_du)), jnp.stack(jax.tree.leaves(du_du))\n",
    "        \n",
    "            ds_dtheta = diag_rtrl_update(ds_du,E,ds_dp)\n",
    "            E = diag_rtrl_update(du_du,E,du_dp)\n",
    "            #print(self.E)\n",
    "            #print(E)\n",
    "            #self.E.value = E\n",
    "\n",
    "            return (out,state,E), (ds_dtheta,f_vjp)\n",
    "\n",
    "        def exec_bwd(res,g):\n",
    "            ds_dtheta,f_vjp = res\n",
    "            grad = jax.tree.map(lambda x: g[0]*x,ds_dtheta)\n",
    "            passback = jax.tree.leaves(f_vjp(g[0]))[0]\n",
    "            #print(g)\n",
    "            return (None,grad,None,None,passback)\n",
    "        \n",
    "        exec_model.defvjp(exec, exec_bwd)\n",
    "        graph, param, state = nnx.split(self.mdl,nnx.Param,...)\n",
    "        vp_exec = partial(jax.vmap(partial(exec_model,graph,param)),state,self.E.value)\n",
    "        if len(x.shape)<2:\n",
    "            x = x.reshape(1,-1)\n",
    "        try:\n",
    "            out,state,E = vp_exec(x)\n",
    "        except:\n",
    "            vp_exec = partial(jax.vmap(partial(exec_model,graph,param,state)),self.E.value)\n",
    "            out,state,E = vp_exec(x)\n",
    "        self.E.value = E\n",
    "        nnx.update(self.mdl,state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jax\n",
    "# import jax.numpy as jnp\n",
    "# import flax.linen as nn\n",
    "# from flax import nnx\n",
    "# from typing import Any, Sequence\n",
    "# from jax.tree_util import Partial, tree_leaves, tree_map\n",
    "# from jax.lax import stop_gradient as stop_grad\n",
    "# from jax.flatten_util import ravel_pytree\n",
    "# from slax.models.utils import reinit_model, connect, RNN\n",
    "# from slax.train.helpers import output, sum_output, diag, rtrl_update, diag_rtrl_update\n",
    "# from functools import partial\n",
    "\n",
    "# class diag_rtrl(nnx.Module):\n",
    "#     def __init__(self, mdl, input, diagonal_sum=True):\n",
    "#         self.mdl = mdl\n",
    "#         graph,param,state = nnx.split(mdl,nnx.Param,...)\n",
    "#         E = [jax.tree.map(lambda x: jnp.zeros(x.size),param)]*len(jax.tree.leaves(state))\n",
    "#         #self.E = nnx.Variable(jax.tree.map(lambda *args: jnp.stack(batch_sz*[jnp.stack(args)]),*E))\n",
    "#         self.E = nnx.Variable(jax.tree.map(lambda *args: jnp.stack(args),*E))\n",
    "#         self.diagonal_sum = diagonal_sum\n",
    "#     @nnx.jit\n",
    "#     def __call__(self,x):\n",
    "#         @jax.custom_vjp\n",
    "#         def exec_model(graph,param,state,E,x):\n",
    "#             model = nnx.merge(graph,param,state)\n",
    "#             out = model(x)\n",
    "#             return out, nnx.split(model,nnx.Param,...)[2], E\n",
    "        \n",
    "#         def exec(graph,param,state,E,x):\n",
    "#             if self.diagonal_sum:\n",
    "#                 ((ds_dp,ds_du),(du_dp,du_du)),(out,state,f_vjp) = jax.jacrev(sum_output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "#             else:\n",
    "#                 grads,(out,state,f_vjp) = jax.jacrev(output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "#                 (ds_grad),(du_dp,du_du) = jax.tree.map(diag,grads)\n",
    "#                 ds_dp,ds_du = jax.tree.map(lambda x: x[0],ds_grad)\n",
    "            \n",
    "#             #print(du_du)\n",
    "#             #print(ds_du)\n",
    "#             ds_du, du_du = jnp.stack(jax.tree.leaves(ds_du)), jnp.stack(jax.tree.leaves(du_du))\n",
    "        \n",
    "#             ds_dtheta = diag_rtrl_update(ds_du,E,ds_dp)\n",
    "#             E = diag_rtrl_update(du_du,E,du_dp)\n",
    "\n",
    "#             return (out,state,E), (ds_dtheta,f_vjp)\n",
    "\n",
    "#         def exec_bwd(res,g):\n",
    "#             ds_dtheta,f_vjp = res\n",
    "#             grad = jax.tree.map(lambda x: g[0]*x,ds_dtheta)\n",
    "#             passback = jax.tree.leaves(f_vjp(g[0]))[0]\n",
    "#             return (None,grad,None,None,passback)\n",
    "        \n",
    "#         exec_model.defvjp(exec, exec_bwd)\n",
    "#         graph, param, state = nnx.split(self.mdl,nnx.Param,...)\n",
    "#         vp_exec = partial(jax.vmap(partial(exec_model,graph,param)),state,self.E.value)\n",
    "#         if len(x.shape)<2:\n",
    "#             x = x.reshape(1,-1)\n",
    "#         #try:\n",
    "#         out,state,E = exec_model(graph,param,state,self.E.value,x)\n",
    "#         # except:\n",
    "#         #     vp_exec = partial(jax.vmap(partial(exec_model,graph,param,state)),self.E.value)\n",
    "#         #     out,state,E = vp_exec(x)\n",
    "#         self.E.value = E\n",
    "#         nnx.update(self.mdl,state)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax.linen as nn\n",
    "from flax import nnx\n",
    "from typing import Any, Sequence\n",
    "from jax.tree_util import Partial, tree_leaves, tree_map\n",
    "from jax.lax import stop_gradient as stop_grad\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from slax.models.utils import reinit_model, connect, RNN\n",
    "from slax.train.helpers import output, sum_output, diag, rtrl_update, diag_rtrl_update\n",
    "from functools import partial\n",
    "\n",
    "def map_stack(x,len_state):\n",
    "    p_sum = lambda x,y: jnp.sum(x,axis=list(range(-1,-y -1,-1)))\n",
    "    out = jnp.stack(jax.tree.leaves(jax.tree.map(p_sum,x,len_state)))\n",
    "    #print(out)\n",
    "    return out\n",
    "\n",
    "def map_stack2(x,len_state):\n",
    "    p_sum = lambda y: jnp.sum(x,axis=list(range(-1,-y -1,-1)))\n",
    "    out = jnp.stack(jax.tree.leaves(jax.tree.map(p_sum,len_state)))\n",
    "    #print(out)\n",
    "    return out\n",
    "\n",
    "def sum_last(x):\n",
    "    return jnp.stack(jax.tree.leaves(jax.tree.map(partial(jnp.sum,axis=-1),(x,))))\n",
    "\n",
    "def sum_output(graph,param,state,x):\n",
    "    len_state = jax.tree.map(lambda x: len(x.shape),state)\n",
    "    def forward(x):\n",
    "        model = nnx.merge(graph,param,state)\n",
    "        out = model(x)\n",
    "        return out, nnx.split(model,nnx.Param,...)[2]\n",
    "    (out,f_vjp,state) = jax.vjp(forward,x,has_aux=True)\n",
    "    return (sum_last(out),sum_last(state),map_stack2(out,len_state),map_stack(state,len_state)),(out,state,f_vjp)\n",
    "\n",
    "def d_sum(a,b):\n",
    "    l = len(a.shape)\n",
    "    return jnp.einsum(a,list(range(l)),b,[0]+list(range(2,l-1))+[Ellipsis]+[l-1],list(range(1,l-1))+[Ellipsis]+[l-1])\n",
    "\n",
    "def d2_sum(a,b):\n",
    "    l = len(a.shape)\n",
    "    out = jnp.einsum(a,list(range(l)),b,list(range(l-1))+[Ellipsis]+[l-1],[Ellipsis]+[l-1])\n",
    "    return out\n",
    "\n",
    "def diag_rtrl_update(x,y,z):\n",
    "    b = jax.tree.map(lambda r,t: r+0*t,y,z)\n",
    "    out = jax.tree.map(lambda inp, ds: d_sum(x,inp) + ds,b,z)\n",
    "    return out\n",
    "\n",
    "def calc_grad(x,y):\n",
    "    out = jax.tree.map(lambda inp: d2_sum(x,inp),y)\n",
    "    return out\n",
    "\n",
    "def calc_E(state,params):\n",
    "    shape = jnp.stack(jax.tree.leaves(state)).shape[:-1]\n",
    "    E = jax.tree.map(lambda x: jnp.zeros(shape + x.shape),params)\n",
    "    return E\n",
    "\n",
    "\n",
    "class diag_rtrl(nnx.Module):\n",
    "    def __init__(self, mdl, diagonal_sum=True):\n",
    "        self.mdl = mdl\n",
    "        graph,param,state = nnx.split(mdl,nnx.Param,...)\n",
    "        self.E = nnx.Variable(jax.tree.map(lambda x: jnp.array([0.],dtype=x.dtype),param))\n",
    "        self.diagonal_sum = diagonal_sum\n",
    "    @nnx.jit\n",
    "    def __call__(self,x):\n",
    "        @jax.custom_vjp\n",
    "        def exec_model(graph,param,state,E,x):\n",
    "            model = nnx.merge(graph,param,state)\n",
    "            out = model(x)\n",
    "            state = nnx.split(model,nnx.Param,...)[2]\n",
    "            E = calc_E(state,param)\n",
    "            return out, state, E\n",
    "        #@jax.jit\n",
    "        def exec(graph,param,state,E,x):\n",
    "            if self.diagonal_sum:\n",
    "                ((ds_dp,_),(du_dp,_),(_,ds_du),(_,du_du)),(out,state,f_vjp) = jax.jacrev(sum_output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "            else:\n",
    "                grads,(out,state,f_vjp) = jax.jacrev(output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "                (ds_grad),(du_dp,du_du) = jax.tree.map(diag,grads)\n",
    "                ds_dp,ds_du = jax.tree.map(lambda x: x[0],ds_grad)\n",
    "            \n",
    "            ds_du, du_du = jnp.stack(jax.tree.leaves(ds_du)), jnp.stack(jax.tree.leaves(du_du))\n",
    "        \n",
    "            ds_dtheta = diag_rtrl_update(ds_du,E,ds_dp)\n",
    "            E = diag_rtrl_update(du_du,E,du_dp)\n",
    "            return (out,state,E), (ds_dtheta,f_vjp)\n",
    "\n",
    "        def exec_bwd(res,g):\n",
    "            ds_dtheta,f_vjp = res\n",
    "            gr = jnp.stack(jax.tree.leaves((g[0],)))\n",
    "            grad = calc_grad(gr,ds_dtheta)\n",
    "            passback = jax.tree.leaves(f_vjp(g[0]))[0]\n",
    "\n",
    "            return (None,grad,None,None,passback)\n",
    "        \n",
    "        exec_model.defvjp(exec, exec_bwd)\n",
    "        graph, param, state = nnx.split(self.mdl,nnx.Param,...)\n",
    "        out,state,E = exec_model(graph,param,state,self.E.value,x)\n",
    "        self.E.value = E\n",
    "        nnx.update(self.mdl,state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax.linen as nn\n",
    "from flax import nnx\n",
    "from typing import Any, Sequence\n",
    "from jax.tree_util import Partial, tree_leaves, tree_map\n",
    "from jax.lax import stop_gradient as stop_grad\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from slax.models.utils import reinit_model, connect, RNN\n",
    "from slax.train.helpers import output, sum_output, diag, rtrl_update, diag_rtrl_update\n",
    "from functools import partial\n",
    "\n",
    "def map_stack(x,len_state):\n",
    "    p_sum = lambda x,y: jnp.sum(x,axis=list(range(-1,-y -1,-1)))\n",
    "    out = jnp.stack(jax.tree.leaves(jax.tree.map(p_sum,x,len_state)))\n",
    "    return out\n",
    "\n",
    "def map_stack2(x,len_state):\n",
    "    p_sum = lambda y: jnp.sum(x,axis=list(range(-1,-y -1,-1)))\n",
    "    out = jnp.stack(jax.tree.leaves(jax.tree.map(p_sum,len_state)))\n",
    "    return out\n",
    "\n",
    "def sum_last(x):\n",
    "    return jnp.stack(jax.tree.leaves(jax.tree.map(partial(jnp.sum,axis=-1),(x,))))\n",
    "\n",
    "def sum_output(graph,param,state,x):\n",
    "    len_state = jax.tree.map(lambda x: len(x.shape),state)\n",
    "    def forward(x):\n",
    "        model = nnx.merge(graph,param,state)\n",
    "        out = model(x)\n",
    "        return out, nnx.split(model,nnx.Param,...)[2]\n",
    "    (out,f_vjp,state) = jax.vjp(forward,x,has_aux=True)\n",
    "    return (sum_last(out),sum_last(state),map_stack2(out,len_state),map_stack(state,len_state)),(out,state,f_vjp)\n",
    "\n",
    "def d_sum(a,b):\n",
    "    l = len(a.shape)\n",
    "    print('here')\n",
    "    l1 = list(range(l))\n",
    "    l2 = [0]+list(range(2,l-1))+[Ellipsis]+[l-1]\n",
    "    l3 = list(range(1,l-1))+[Ellipsis]+[l-1]\n",
    "    print(l1,l2,l3)\n",
    "    return jnp.einsum(a,list(range(l)),b,[0]+list(range(2,l-1))+[Ellipsis]+[l-1],list(range(1,l-1))+[Ellipsis]+[l-1])\n",
    "\n",
    "def d2_sum(a,b):\n",
    "    l = len(a.shape)\n",
    "    print('there')\n",
    "    out = jnp.einsum(a,list(range(l)),b,list(range(l-1))+[Ellipsis]+[l-1],[Ellipsis]+[l-1])\n",
    "    return out\n",
    "\n",
    "def diag_rtrl_update(x,y,z):\n",
    "    b = jax.tree.map(lambda r,t: r+0*t,y,z)\n",
    "    out = jax.tree.map(lambda inp, ds: d_sum(x,inp) + ds,b,z)\n",
    "    return out\n",
    "\n",
    "def calc_grad(x,y):\n",
    "    out = jax.tree.map(lambda inp: d2_sum(x,inp),y)\n",
    "    return out\n",
    "\n",
    "def calc_E(state,params):\n",
    "    shape = jnp.stack(jax.tree.leaves(state)).shape[:-1]\n",
    "    E = jax.tree.map(lambda x: jnp.zeros(shape + x.shape),params)\n",
    "    return E\n",
    "\n",
    "\n",
    "class diag_rtrl(nnx.Module):\n",
    "    def __init__(self, mdl, diagonal_sum=True):\n",
    "        self.mdl = mdl\n",
    "        graph,param,state = nnx.split(mdl,nnx.Param,...)\n",
    "        self.E = nnx.Variable(jax.tree.map(lambda x: jnp.array([0.],dtype=x.dtype),param))\n",
    "        self.diagonal_sum = diagonal_sum\n",
    "    @nnx.jit\n",
    "    def __call__(self,x):\n",
    "        @jax.custom_vjp\n",
    "        def exec_model(graph,param,state,E,x):\n",
    "            model = nnx.merge(graph,param,state)\n",
    "            out = model(x)\n",
    "            state = nnx.split(model,nnx.Param,...)[2]\n",
    "            E = calc_E(state,param)\n",
    "            return out, state, E\n",
    "        #@jax.jit\n",
    "        def exec(graph,param,state,E,x):\n",
    "            if self.diagonal_sum:\n",
    "                ((ds_dp,_),(du_dp,_),(_,ds_du),(_,du_du)),(out,state,f_vjp) = jax.jacrev(sum_output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "            else:\n",
    "                grads,(out,state,f_vjp) = jax.jacrev(output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "                (ds_grad),(du_dp,du_du) = jax.tree.map(diag,grads)\n",
    "                ds_dp,ds_du = jax.tree.map(lambda x: x[0],ds_grad)\n",
    "            \n",
    "            ds_du, du_du = jnp.stack(jax.tree.leaves(ds_du)), jnp.stack(jax.tree.leaves(du_du))\n",
    "        \n",
    "            ds_dtheta = diag_rtrl_update(ds_du,E,ds_dp)\n",
    "            E = diag_rtrl_update(du_du,E,du_dp)\n",
    "            return (out,state,E), (ds_dtheta,f_vjp)\n",
    "\n",
    "        def exec_bwd(res,g):\n",
    "            ds_dtheta,f_vjp = res\n",
    "            gr = jnp.stack(jax.tree.leaves((g[0],)))\n",
    "            grad = calc_grad(gr,ds_dtheta)\n",
    "            passback = jax.tree.leaves(f_vjp(g[0]))[0]\n",
    "\n",
    "            return (None,grad,None,None,passback)\n",
    "        \n",
    "        exec_model.defvjp(exec, exec_bwd)\n",
    "        graph, param, state = nnx.split(self.mdl,nnx.Param,...)\n",
    "        out,state,E = exec_model(graph,param,state,self.E.value,x)\n",
    "        self.E.value = E\n",
    "        nnx.update(self.mdl,state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OTTT(nnx.Module):\n",
    "    def __init__(self, mdl, diagonal_sum=True):\n",
    "        self.mdl = mdl\n",
    "        graph,param,state = nnx.split(mdl,nnx.Param,...)\n",
    "        self.E = nnx.Variable(jax.tree.map(lambda x: jnp.array([0.],dtype=x.dtype),param))\n",
    "        self.diagonal_sum = diagonal_sum\n",
    "    @nnx.jit\n",
    "    def __call__(self,x):\n",
    "        @jax.custom_vjp\n",
    "        def exec_model(graph,param,state,E,x):\n",
    "            model = nnx.merge(graph,param,state)\n",
    "            out = model(x)\n",
    "            state = nnx.split(model,nnx.Param,...)[2]\n",
    "            E = calc_E(state,param)\n",
    "            return out, state, E\n",
    "        #@jax.jit\n",
    "        def exec(graph,param,state,E,x):\n",
    "            if self.diagonal_sum:\n",
    "                ((ds_dp,_),(du_dp,_),(_,ds_du),(_,du_du)),(out,state,f_vjp) = jax.jacrev(sum_output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "            else:\n",
    "                grads,(out,state,f_vjp) = jax.jacrev(output,argnums=[1,2],has_aux=True)(graph,param,state,x)\n",
    "                (ds_grad),(du_dp,du_du) = jax.tree.map(diag,grads)\n",
    "                ds_dp,ds_du = jax.tree.map(lambda x: x[0],ds_grad)\n",
    "            \n",
    "            ds_du, du_du = jnp.stack(jax.tree.leaves(ds_du)), jnp.stack(jax.tree.leaves(du_du))\n",
    "        \n",
    "            ds_dtheta = diag_rtrl_update(ds_du,E,ds_dp)\n",
    "            E = diag_rtrl_update(du_du,E,du_dp)\n",
    "            return (out,state,E), (ds_dtheta,f_vjp)\n",
    "\n",
    "        def exec_bwd(res,g):\n",
    "            ds_dtheta,f_vjp = res\n",
    "            gr = jnp.stack(jax.tree.leaves((g[0],)))\n",
    "            grad = calc_grad(gr,ds_dtheta)\n",
    "            passback = jax.tree.leaves(f_vjp(g[0]))[0]\n",
    "\n",
    "            return (None,grad,None,None,passback)\n",
    "        \n",
    "        exec_model.defvjp(exec, exec_bwd)\n",
    "        graph, param, state = nnx.split(self.mdl,nnx.Param,...)\n",
    "        out,state,E = exec_model(graph,param,state,self.E.value,x)\n",
    "        self.E.value = E\n",
    "        nnx.update(self.mdl,state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = sl.randman(manifold_key,random_seed,nb_classes=output_sz,nb_units=input_sz,nb_steps=seq_len,nb_samples=100,batch_sz=batch_sz,dim_manifold=2,alpha=2.,dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = sl.connect([nnx.Linear(64,100,rngs=nnx_key),\n",
    "                  sl.LIF(100),\n",
    "                  nnx.Linear(100,100,rngs=nnx_key),\n",
    "                  sl.LIF(100),\n",
    "                  nnx.Linear(100,100,rngs=nnx_key),\n",
    "                  sl.LIF(100)],cat={4:[1,2],2:[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn(jnp.zeros_like(batch[0][0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = sl.connect([nnx.Linear(64,100,rngs=nnx_key),\n",
    "                  sl.LIF(100)])\n",
    "l2 = sl.connect([nnx.Linear(100,100,rngs=nnx_key),\n",
    "                  sl.LIF(100)])\n",
    "l3 = sl.connect([nnx.Linear(100,10,rngs=nnx_key),\n",
    "                  sl.LIF(10)])\n",
    "snn = sl.connect([l1,l2,l3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.random.truncated_normal(jax.random.PRNGKey(0),-0.5,2.,(20,32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x158abdee0>, update=<function chain.<locals>.update_fn at 0x158abe020>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optax.adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = sl.connect([nnx.Linear(64,10,rngs=nnx.Rngs(0)),#nnx_key),\n",
    "                  sl.LIF(10)])\n",
    "#snn(jnp.zeros_like(batch[0][0]))\n",
    "g,p = nnx.split(snn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph1,p1,s1 = nnx.split(snn,nnx.Param,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 32, 64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = sl.connect([nnx.Conv(64,100,2,rngs=nnx.Rngs(0)),\n",
    "                  sl.LIF(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = sl.diag_rtrl(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.grad\n",
    "def loss(snn):\n",
    "    snn(batch[0])\n",
    "    return jnp.sum(snn(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "there\n",
      "there\n",
      "there\n",
      "there\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: /var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/247473262.py:4:19: error: failed to legalize operation 'mhlo.dot_general'\n/var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/247473262.py:4:19: note: called from\n/var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/3462137631.py:1:0: note: called from\n<frozen runpy>:88:4: note: called from\n<frozen runpy>:198:11: note: called from\n/var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/247473262.py:4:19: note: see current operation: %667 = \"mhlo.dot_general\"(%1, %613) {dot_dimension_numbers = #mhlo.dot<lhs_batching_dimensions = [3], rhs_batching_dimensions = [3], lhs_contracting_dimensions = [0, 1, 2], rhs_contracting_dimensions = [0, 1, 2]>} : (tensor<1x50x32x100xf32>, tensor<1x50x32x100xf32>) -> tensor<100xf32>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/snn/lib/python3.12/site-packages/flax/nnx/nnx/graph.py:1158\u001b[0m, in \u001b[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_context_manager_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1157\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/snn/lib/python3.12/site-packages/flax/nnx/nnx/transforms/compilation.py:343\u001b[0m, in \u001b[0;36mjit.<locals>.jit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;129m@graph\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    337\u001b[0m   pure_args, pure_kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[1;32m    338\u001b[0m     (args, kwargs),\n\u001b[1;32m    339\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m(in_shardings, kwarg_shardings),\n\u001b[1;32m    340\u001b[0m     split_fn\u001b[38;5;241m=\u001b[39m_jit_split_fn,\n\u001b[1;32m    341\u001b[0m     ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    342\u001b[0m   )\n\u001b[0;32m--> 343\u001b[0m   pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m \u001b[43mjitted_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_kwargs\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m   _args_out, _kwargs_out, out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(\n\u001b[1;32m    347\u001b[0m     (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    348\u001b[0m   )\n\u001b[1;32m    349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/snn/lib/python3.12/site-packages/jax/_src/compiler.py:267\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    262\u001b[0m         built_c, compile_options\u001b[38;5;241m=\u001b[39moptions, host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks\n\u001b[1;32m    263\u001b[0m     )\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    265\u001b[0m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    266\u001b[0m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m xc\u001b[38;5;241m.\u001b[39mXlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m error_handler \u001b[38;5;129;01min\u001b[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: /var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/247473262.py:4:19: error: failed to legalize operation 'mhlo.dot_general'\n/var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/247473262.py:4:19: note: called from\n/var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/3462137631.py:1:0: note: called from\n<frozen runpy>:88:4: note: called from\n<frozen runpy>:198:11: note: called from\n/var/folders/dq/p881jxbs2mv4605904hzdh_m0000gn/T/ipykernel_70667/247473262.py:4:19: note: see current operation: %667 = \"mhlo.dot_general\"(%1, %613) {dot_dimension_numbers = #mhlo.dot<lhs_batching_dimensions = [3], rhs_batching_dimensions = [3], lhs_contracting_dimensions = [0, 1, 2], rhs_contracting_dimensions = [0, 1, 2]>} : (tensor<1x50x32x100xf32>, tensor<1x50x32x100xf32>) -> tensor<100xf32>\n"
     ]
    }
   ],
   "source": [
    "nnx.jit(loss)(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "here\n",
      "[0, 1, 2, 3, 4] [0, 2, 3, Ellipsis, 4] [1, 2, 3, Ellipsis, 4]\n",
      "there\n",
      "there\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State({\n",
       "  'mdl': {\n",
       "    'chain': {\n",
       "      0: {\n",
       "        'bias': VariableState(\n",
       "          type=Param,\n",
       "          value=Array([36.859505, 34.669376, 42.61126 , 35.8621  , 53.016445, 53.236927,\n",
       "                 37.213726, 31.184767, 31.964853, 49.11505 , 44.383484, 42.263897,\n",
       "                 50.154522, 49.15603 , 42.22688 , 49.03219 , 36.944378, 41.569527,\n",
       "                 41.223507, 31.440027, 35.446568, 44.250008, 41.529305, 79.44324 ,\n",
       "                 35.325672, 41.03851 , 33.03958 , 54.344788, 45.67574 , 32.7691  ,\n",
       "                 66.08645 , 46.1172  , 43.919514, 57.4566  , 38.971127, 47.911144,\n",
       "                 46.625263, 21.642653, 39.134327, 28.507574, 66.46318 , 66.53866 ,\n",
       "                 40.005962, 32.81882 , 40.212605, 43.32193 , 34.516582, 55.11848 ,\n",
       "                 53.292496, 62.50898 , 33.44934 , 35.594994, 44.201965, 40.968525,\n",
       "                 60.474503, 38.183308, 25.913815, 50.615295, 36.270576, 45.56291 ,\n",
       "                 67.97275 , 42.040436, 52.78253 , 35.03741 , 28.569239, 32.636974,\n",
       "                 83.10499 , 37.43508 , 44.60581 , 19.355877, 25.49256 , 42.859016,\n",
       "                 23.333239, 33.195526, 71.81282 , 45.895195, 63.99669 , 31.187569,\n",
       "                 22.003857, 71.90461 , 37.69144 , 52.532402, 36.532497, 82.71603 ,\n",
       "                 28.040392, 52.633064, 39.34447 , 29.076916, 33.818707, 32.608593,\n",
       "                 29.322945, 56.542675, 36.89136 , 35.12956 , 48.169525, 42.67607 ,\n",
       "                 43.00471 , 40.10951 , 68.75623 , 22.114487], dtype=float32)\n",
       "        ),\n",
       "        'kernel': VariableState(\n",
       "          type=Param,\n",
       "          value=Array([[[2.117637  , 0.12077701, 0.14471428, ..., 1.2225684 ,\n",
       "                   0.6491041 , 0.06921981],\n",
       "                  [0.5349572 , 0.6602013 , 0.28438887, ..., 1.481152  ,\n",
       "                   1.3454653 , 0.5905105 ],\n",
       "                  [0.38433337, 1.9835212 , 0.8583923 , ..., 2.869487  ,\n",
       "                   3.8114185 , 5.3409705 ],\n",
       "                  ...,\n",
       "                  [1.4097894 , 1.8145877 , 5.8102345 , ..., 0.6932823 ,\n",
       "                   0.33023542, 0.62058496],\n",
       "                  [1.206228  , 1.4378114 , 0.80382   , ..., 0.20026064,\n",
       "                   3.8757238 , 0.25095963],\n",
       "                  [0.18437573, 1.8853939 , 0.7817585 , ..., 7.256383  ,\n",
       "                   1.4590994 , 0.17823195]],\n",
       "          \n",
       "                 [[0.8685298 , 1.2939477 , 0.7901819 , ..., 2.6710238 ,\n",
       "                   0.6849279 , 0.13925397],\n",
       "                  [0.22160521, 1.1746824 , 0.36208892, ..., 0.88277483,\n",
       "                   0.18483847, 0.19381022],\n",
       "                  [1.0668776 , 2.194659  , 3.3486004 , ..., 0.5479888 ,\n",
       "                   1.9586605 , 0.08134745],\n",
       "                  ...,\n",
       "                  [0.19717744, 0.30355778, 0.19313174, ..., 0.12447497,\n",
       "                   4.1761603 , 0.06701407],\n",
       "                  [0.96220565, 0.17050397, 0.75175333, ..., 0.2539136 ,\n",
       "                   2.1610782 , 0.8288711 ],\n",
       "                  [0.60592014, 0.34098965, 0.4170142 , ..., 1.2180595 ,\n",
       "                   2.188334  , 0.17394976]]], dtype=float32)\n",
       "        )\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = sl.connect([nnx.Linear(64,100,rngs=nnx_key),\n",
    "                  sl.LIF(100)])\n",
    "l2 = sl.connect([nnx.Linear(100,100,rngs=nnx_key),\n",
    "                  sl.LIF(100)])\n",
    "l3 = sl.connect([nnx.Linear(100,10,rngs=nnx_key),\n",
    "                  sl.LIF(10)])\n",
    "snn = sl.connect([l1,l2,l3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr1,s1 = nnx.split(l1)\n",
    "gr2,s2 = nnx.split(l2)\n",
    "gr3,s3 = nnx.split(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = (x,batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = sl.train_offline(snn,optax.softmax_cross_entropy,optax.adam(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    train_step(batch)\n",
    "    batch = sl.randman(manifold_key,random_seed+i+1,nb_classes=output_sz,nb_units=input_sz,nb_steps=seq_len,nb_samples=100,batch_sz=batch_sz,dim_manifold=2,alpha=2.,dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr1,s1 = nnx.split(snn.chain[0])\n",
    "gr2,s2 = nnx.split(snn.chain[1])\n",
    "gr3,s3 = nnx.split(snn.chain[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = sl.train_offline(snn,optax.softmax_cross_entropy,optax.adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = train_step.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nnx.merge(gr1,s1)\n",
    "l2 = nnx.merge(gr2,s2)\n",
    "l3 = nnx.merge(gr3,s3)\n",
    "snn = sl.connect([l1,l2,l3])\n",
    "\n",
    "train_step = sl.train_online_deferred(snn,optax.softmax_cross_entropy,optax.adam(0.001))\n",
    "train_step(batch)\n",
    "g3 = train_step.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = diag_rtrl(nnx.merge(gr1,s1),batch_sz)\n",
    "l2 = diag_rtrl(nnx.merge(gr2,s2),batch_sz)\n",
    "l3 = diag_rtrl(nnx.merge(gr3,s3),batch_sz)\n",
    "snn = sl.connect([l1,l2,l3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.grad\n",
    "def loss(snn):\n",
    "    return jnp.sum(snn(batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snn(batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snn.chain[0].E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss(snn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl = sl.connect([nnx.Linear(64,10,rngs=nnx_key),\n",
    "#                   sl.LIF(10)])\n",
    "# g,p = nnx.split(mdl)\n",
    "#snn = diag_rtrl(nnx.merge(g,p),32,True)\n",
    "#snn(jnp.zeros_like(batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g,p,s = nnx.split(snn,nnx.Param,...)\n",
    "#snn = nnx.merge(g,p,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = sl.train_online_deferred(snn,optax.softmax_cross_entropy,optax.adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = train_step.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "ostl_alignment = sl.layerwise_cosine_similarity(jax.tree.leaves(g1),jax.tree.leaves(g2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_alignment = sl.layerwise_cosine_similarity(jax.tree.leaves(g1),jax.tree.leaves(g3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array(0.771285, dtype=float32),\n",
       " Array(0.998138, dtype=float32),\n",
       " Array(1., dtype=float32)]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ostl_alignment[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array(0.3779749, dtype=float32),\n",
       " Array(0.767234, dtype=float32),\n",
       " Array(0.9948083, dtype=float32)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_alignment[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x4327b9dc0>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.bar([0.05,1.05,2.05],ostl_alignment[1::2][::-1],0.4,color='#7fc97f',edgecolor='k')\n",
    "plt.bar([0.45,1.45,2.45],bp_alignment[1::2][::-1],0.4,color='#beaed4',edgecolor='k')\n",
    "plt.xticks([0.25,1.25,2.25],['Output','Layer 2','Layer 1'])\n",
    "plt.xlabel('Layer Kernel',fontsize=16)\n",
    "plt.ylabel('Gradient Cosine Similarity to BPTT',fontsize=16)\n",
    "plt.legend(['OSTL','BackProp (No Unrolling)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "@nnx.grad\n",
    "def loss(mdl,x):\n",
    "    return jnp.sum(mdl(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ostl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[314], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jnp\u001b[38;5;241m.\u001b[39msum(jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mleaves(\u001b[43mostl\u001b[49m\u001b[38;5;241m.\u001b[39mE\u001b[38;5;241m.\u001b[39mvalue)[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ostl' is not defined"
     ]
    }
   ],
   "source": [
    "jnp.sum(jax.tree.leaves(ostl.E.value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State({\n",
      "  'chain': {\n",
      "    0: {\n",
      "      'chain': {\n",
      "        1: {\n",
      "          'Vmem': VariableState(\n",
      "            type=Variable,\n",
      "            value=Traced<ShapedArray(float32[3,100])>with<BatchTrace(level=5/0)> with\n",
      "              val = Traced<ShapedArray(float32[32,3,100])>with<DynamicJaxprTrace(level=4/0)>\n",
      "              batch_dim = 0\n",
      "          )\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    1: {\n",
      "      'chain': {\n",
      "        1: {\n",
      "          'Vmem': VariableState(\n",
      "            type=Variable,\n",
      "            value=Traced<ShapedArray(float32[3,100])>with<BatchTrace(level=5/0)> with\n",
      "              val = Traced<ShapedArray(float32[32,3,100])>with<DynamicJaxprTrace(level=4/0)>\n",
      "              batch_dim = 0\n",
      "          )\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    2: {\n",
      "      'chain': {\n",
      "        1: {\n",
      "          'Vmem': VariableState(\n",
      "            type=Variable,\n",
      "            value=Traced<ShapedArray(float32[3,10])>with<BatchTrace(level=5/0)> with\n",
      "              val = Traced<ShapedArray(float32[32,3,10])>with<DynamicJaxprTrace(level=4/0)>\n",
      "              batch_dim = 0\n",
      "          )\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All input arrays must have the same shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[0;32m<frozen runpy>:198\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen runpy>:88\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel_launcher.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipykernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[0;32m---> 17\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/traitlets/config/application.py:1043\u001b[0m, in \u001b[0;36mlaunch_instance\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1042\u001b[0m app\u001b[38;5;241m.\u001b[39minitialize(argv)\n\u001b[0;32m-> 1043\u001b[0m app\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel/kernelapp.py:736\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/tornado/platform/asyncio.py:195\u001b[0m, in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop\u001b[38;5;241m.\u001b[39mrun_forever()\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/asyncio/base_events.py:607\u001b[0m, in \u001b[0;36mrun_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/asyncio/base_events.py:1922\u001b[0m, in \u001b[0;36m_run_once\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1922\u001b[0m         handle\u001b[38;5;241m.\u001b[39m_run()\n\u001b[1;32m   1923\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/asyncio/events.py:80\u001b[0m, in \u001b[0;36m_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel/kernelbase.py:516\u001b[0m, in \u001b[0;36mdispatch_queue\u001b[0;34m()\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_one()\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel/kernelbase.py:505\u001b[0m, in \u001b[0;36mprocess_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m dispatch(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel/kernelbase.py:412\u001b[0m, in \u001b[0;36mdispatch_shell\u001b[0;34m()\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel/kernelbase.py:740\u001b[0m, in \u001b[0;36mexecute_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(reply_content):\n\u001b[0;32m--> 740\u001b[0m     reply_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m reply_content\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel/ipkernel.py:422\u001b[0m, in \u001b[0;36mdo_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_cell_id:\n\u001b[0;32m--> 422\u001b[0m     res \u001b[38;5;241m=\u001b[39m shell\u001b[38;5;241m.\u001b[39mrun_cell(\n\u001b[1;32m    423\u001b[0m         code,\n\u001b[1;32m    424\u001b[0m         store_history\u001b[38;5;241m=\u001b[39mstore_history,\n\u001b[1;32m    425\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    426\u001b[0m         cell_id\u001b[38;5;241m=\u001b[39mcell_id,\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/ipykernel/zmqshell.py:546\u001b[0m, in \u001b[0;36mrun_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_cell(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3009\u001b[0m, in \u001b[0;36mrun_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3009\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_cell(\n\u001b[1;32m   3010\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[1;32m   3011\u001b[0m     )\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3064\u001b[0m, in \u001b[0;36m_run_cell\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3064\u001b[0m     result \u001b[38;5;241m=\u001b[39m runner(coro)\n\u001b[1;32m   3065\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/IPython/core/async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3269\u001b[0m, in \u001b[0;36mrun_cell_async\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3266\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n\u001b[0;32m-> 3269\u001b[0m has_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ast_nodes(code_ast\u001b[38;5;241m.\u001b[39mbody, cell_name,\n\u001b[1;32m   3270\u001b[0m        interactivity\u001b[38;5;241m=\u001b[39minteractivity, compiler\u001b[38;5;241m=\u001b[39mcompiler, result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[1;32m   3272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_raised\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3448\u001b[0m, in \u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3447\u001b[0m     asy \u001b[38;5;241m=\u001b[39m compare(code)\n\u001b[0;32m-> 3448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(code, result, async_\u001b[38;5;241m=\u001b[39masy):\n\u001b[1;32m   3449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m, in \u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3508\u001b[0m         exec(code_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_global_ns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[1;32m   3509\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3510\u001b[0m     \u001b[38;5;66;03m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[438], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss(ostl,batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/graph.py:1158\u001b[0m, in \u001b[0;36mupdate_context_manager_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/compilation.py:343\u001b[0m, in \u001b[0;36mjit_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    337\u001b[0m pure_args, pure_kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[1;32m    338\u001b[0m   (args, kwargs),\n\u001b[1;32m    339\u001b[0m   prefix\u001b[38;5;241m=\u001b[39m(in_shardings, kwarg_shardings),\n\u001b[1;32m    340\u001b[0m   split_fn\u001b[38;5;241m=\u001b[39m_jit_split_fn,\n\u001b[1;32m    341\u001b[0m   ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    342\u001b[0m )\n\u001b[0;32m--> 343\u001b[0m pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m jitted_fn(\n\u001b[1;32m    344\u001b[0m   \u001b[38;5;241m*\u001b[39mpure_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpure_kwargs\n\u001b[1;32m    345\u001b[0m )\n\u001b[1;32m    346\u001b[0m _args_out, _kwargs_out, out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(\n\u001b[1;32m    347\u001b[0m   (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    348\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/compilation.py:111\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree((pure_args, pure_kwargs), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m args_out, kwargs_out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mclear_non_graph_nodes((args, kwargs))\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/graph.py:1158\u001b[0m, in \u001b[0;36mupdate_context_manager_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/autodiff.py:164\u001b[0m, in \u001b[0;36mgrad_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m extract\u001b[38;5;241m.\u001b[39mbroadcast_state(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m, nondiff_states):\n\u001b[0;32m--> 164\u001b[0m   fn_out \u001b[38;5;241m=\u001b[39m gradded_fn(\u001b[38;5;241m*\u001b[39mpure_args)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_grads\u001b[39m(grads):\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/autodiff.py:86\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m args \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(pure_args, merge_fn\u001b[38;5;241m=\u001b[39m_grad_merge_fn, ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     88\u001b[0m args_out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mclear_non_graph_nodes(args)\n",
      "Cell \u001b[0;32mIn[436], line 4\u001b[0m, in \u001b[0;36mloss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@nnx\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@nnx\u001b[39m\u001b[38;5;241m.\u001b[39mgrad\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(mdl,x):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39msum(mdl(x))\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/graph.py:1158\u001b[0m, in \u001b[0;36mupdate_context_manager_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/compilation.py:343\u001b[0m, in \u001b[0;36mjit_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    337\u001b[0m pure_args, pure_kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[1;32m    338\u001b[0m   (args, kwargs),\n\u001b[1;32m    339\u001b[0m   prefix\u001b[38;5;241m=\u001b[39m(in_shardings, kwarg_shardings),\n\u001b[1;32m    340\u001b[0m   split_fn\u001b[38;5;241m=\u001b[39m_jit_split_fn,\n\u001b[1;32m    341\u001b[0m   ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    342\u001b[0m )\n\u001b[0;32m--> 343\u001b[0m pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m jitted_fn(\n\u001b[1;32m    344\u001b[0m   \u001b[38;5;241m*\u001b[39mpure_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpure_kwargs\n\u001b[1;32m    345\u001b[0m )\n\u001b[1;32m    346\u001b[0m _args_out, _kwargs_out, out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(\n\u001b[1;32m    347\u001b[0m   (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    348\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/compilation.py:111\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree((pure_args, pure_kwargs), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m args_out, kwargs_out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mclear_non_graph_nodes((args, kwargs))\n",
      "Cell \u001b[0;32mIn[420], line 75\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     vp_exec \u001b[38;5;241m=\u001b[39m partial(jax\u001b[38;5;241m.\u001b[39mvmap(partial(exec_model,graph,param,state,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mE\u001b[38;5;241m.\u001b[39mvalue)))\n\u001b[0;32m---> 75\u001b[0m     out,state,E \u001b[38;5;241m=\u001b[39m vp_exec(x)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#self.E.value = E\u001b[39;00m\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m: ValueError: All input arrays must have the same shape.\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[438], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mostl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/graph.py:1158\u001b[0m, in \u001b[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_context_manager_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1157\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/compilation.py:343\u001b[0m, in \u001b[0;36mjit.<locals>.jit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;129m@graph\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    337\u001b[0m   pure_args, pure_kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[1;32m    338\u001b[0m     (args, kwargs),\n\u001b[1;32m    339\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m(in_shardings, kwarg_shardings),\n\u001b[1;32m    340\u001b[0m     split_fn\u001b[38;5;241m=\u001b[39m_jit_split_fn,\n\u001b[1;32m    341\u001b[0m     ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    342\u001b[0m   )\n\u001b[0;32m--> 343\u001b[0m   pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m \u001b[43mjitted_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_kwargs\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m   _args_out, _kwargs_out, out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(\n\u001b[1;32m    347\u001b[0m     (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    348\u001b[0m   )\n\u001b[1;32m    349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/compilation.py:111\u001b[0m, in \u001b[0;36mJitFn.__call__\u001b[0;34m(self, *pure_args, **pure_kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mpure_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpure_kwargs):\n\u001b[1;32m    109\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree((pure_args, pure_kwargs), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m   args_out, kwargs_out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mclear_non_graph_nodes((args, kwargs))\n\u001b[1;32m    114\u001b[0m   pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[1;32m    115\u001b[0m     (args_out, kwargs_out, out),\n\u001b[1;32m    116\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_shardings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwarg_shardings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_shardings),\n\u001b[1;32m    117\u001b[0m     ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    118\u001b[0m     split_fn\u001b[38;5;241m=\u001b[39m_jit_split_fn,\n\u001b[1;32m    119\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/graph.py:1158\u001b[0m, in \u001b[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_context_manager_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1157\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/autodiff.py:164\u001b[0m, in \u001b[0;36m_grad_general.<locals>.grad_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    159\u001b[0m pure_args \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[1;32m    160\u001b[0m   args, prefix\u001b[38;5;241m=\u001b[39marg_filters, split_fn\u001b[38;5;241m=\u001b[39m_grad_split_fn, ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m extract\u001b[38;5;241m.\u001b[39mbroadcast_state(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m, nondiff_states):\n\u001b[0;32m--> 164\u001b[0m   fn_out \u001b[38;5;241m=\u001b[39m \u001b[43mgradded_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_grads\u001b[39m(grads):\n\u001b[1;32m    167\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, extract\u001b[38;5;241m.\u001b[39mTreeNode) \u001b[38;5;28;01melse\u001b[39;00m x,\n\u001b[1;32m    169\u001b[0m     grads,\n\u001b[1;32m    170\u001b[0m     is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, extract\u001b[38;5;241m.\u001b[39mTreeNode),\n\u001b[1;32m    171\u001b[0m   )\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/autodiff.py:86\u001b[0m, in \u001b[0;36mGradFn.__call__\u001b[0;34m(self, *pure_args)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mmerge(value\u001b[38;5;241m.\u001b[39mgraphdef, value\u001b[38;5;241m.\u001b[39mstate, nondiff)\n\u001b[1;32m     84\u001b[0m args \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(pure_args, merge_fn\u001b[38;5;241m=\u001b[39m_grad_merge_fn, ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m args_out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mclear_non_graph_nodes(args)\n\u001b[1;32m     89\u001b[0m pure_args_out, pure_out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree((args_out, out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[436], line 4\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(mdl, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@nnx\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@nnx\u001b[39m\u001b[38;5;241m.\u001b[39mgrad\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(mdl,x):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39msum(\u001b[43mmdl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/graph.py:1158\u001b[0m, in \u001b[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_context_manager_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1157\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/flax/nnx/nnx/transforms/compilation.py:343\u001b[0m, in \u001b[0;36mjit.<locals>.jit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;129m@graph\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    337\u001b[0m   pure_args, pure_kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[1;32m    338\u001b[0m     (args, kwargs),\n\u001b[1;32m    339\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m(in_shardings, kwarg_shardings),\n\u001b[1;32m    340\u001b[0m     split_fn\u001b[38;5;241m=\u001b[39m_jit_split_fn,\n\u001b[1;32m    341\u001b[0m     ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    342\u001b[0m   )\n\u001b[0;32m--> 343\u001b[0m   pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m \u001b[43mjitted_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_kwargs\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m   _args_out, _kwargs_out, out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(\n\u001b[1;32m    347\u001b[0m     (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    348\u001b[0m   )\n\u001b[1;32m    349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[420], line 49\u001b[0m, in \u001b[0;36mdiag_rtrl.__call__.<locals>.exec\u001b[0;34m(graph, param, state, E, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m     (ds_grad),(du_dp,du_du) \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(diag,grads)\n\u001b[1;32m     47\u001b[0m     ds_dp,ds_du \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m],ds_grad)\n\u001b[0;32m---> 49\u001b[0m ds_du, du_du \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaves\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_du\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, jnp\u001b[38;5;241m.\u001b[39mstack(jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mleaves(du_du))\n\u001b[1;32m     51\u001b[0m ds_dtheta \u001b[38;5;241m=\u001b[39m diag_rtrl_update(ds_du,E,ds_dp)\n\u001b[1;32m     52\u001b[0m E \u001b[38;5;241m=\u001b[39m diag_rtrl_update(du_du,E,du_dp)\n",
      "File \u001b[0;32m~/miniforge3/envs/jax/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:2841\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[1;32m   2840\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape(a) \u001b[38;5;241m!=\u001b[39m shape0:\n\u001b[0;32m-> 2841\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll input arrays must have the same shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2842\u001b[0m   new_arrays\u001b[38;5;241m.\u001b[39mappend(expand_dims(a, axis))\n\u001b[1;32m   2843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate(new_arrays, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: All input arrays must have the same shape."
     ]
    }
   ],
   "source": [
    "loss(ostl,batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = jax.jit(sl.RNN(snn,False,broadcast_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "out = rm(batch[0])\n",
    "out.block_until_ready()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = jax.jit(sl.RNN(snn,unroll=jnp.iinfo(jnp.uint32).max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "out = rm(batch[0])\n",
    "out.block_until_ready()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = jax.jit(sl.RNN(snn,unroll=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "out = rm(batch[0])\n",
    "out.block_until_ready()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g,p = nnx.split(snn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = g.apply(p)(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.scan(unroll=jnp.iinfo(jnp.uint32).max)\n",
    "def forward(mdl,x):\n",
    "    return mdl,mdl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "@nnx.grad\n",
    "def loss(mdl,batch):\n",
    "    _,y = forward(mdl,batch[0]+2)\n",
    "    return jnp.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = loss(snn,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_axes = nnx.StateAxes({nnx.Param: None, ...:0})\n",
    "@nnx.vmap(in_axes=(state_axes,0),out_axes=0)\n",
    "def forward(mdl,x):\n",
    "    return mdl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(snn,batch[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adamax(0.01)\n",
    "bp_opt_state = optimizer.init(tree_map(jnp.float32,bp_params['params']))\n",
    "ostl_opt_state = optimizer.init(tree_map(jnp.float32,ostl_params['params']))\n",
    "ottt_opt_state = optimizer.init(tree_map(jnp.float32,ottt_params['params']))\n",
    "otpe_opt_state = optimizer.init(tree_map(jnp.float32,otpe_params['params']))\n",
    "rtrl_opt_state = optimizer.init(tree_map(jnp.float32,rtrl_params['params']))\n",
    "fptt_opt_state = optimizer.init(tree_map(jnp.float32,fptt_params['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_train = sl.train_offline(bp_model,optax.softmax_cross_entropy,optimizer)\n",
    "ostl_train = sl.train_online(ostl_model,optax.softmax_cross_entropy,optimizer)\n",
    "ottt_train = sl.train_online(ottt_model,optax.softmax_cross_entropy,optimizer)\n",
    "otpe_train = sl.train_online(otpe_model,optax.softmax_cross_entropy,optimizer)\n",
    "rtrl_train = sl.train_online(rtrl_model,optax.softmax_cross_entropy,optimizer)\n",
    "fptt_train = sl.FPTT(bp_model,optax.softmax_cross_entropy,optimizer)\n",
    "\n",
    "\n",
    "bp_eval = sl.train_offline(bp_model,optax.softmax_cross_entropy,optimizer)\n",
    "ostl_eval = sl.train_online_deferred(ostl_model,optax.softmax_cross_entropy,optimizer)\n",
    "ottt_eval = sl.train_online_deferred(ottt_model,optax.softmax_cross_entropy,optimizer)\n",
    "otpe_eval = sl.train_online_deferred(otpe_model,optax.softmax_cross_entropy,optimizer)\n",
    "rtrl_eval = sl.train_online_deferred(rtrl_model,optax.softmax_cross_entropy,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_,grad = bp_train(bp_params,batch,bp_opt_state,True,unroll=5)\n",
    "out = sl.compare_grads(ostl_eval,bp_params,grad,(ostl_params,batch,ostl_opt_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,_,_,_,grad = bp_train(bp_params,batch,bp_opt_state,True,unroll=5)\n",
    "# out = sl.compare_grads(rtrl_eval,bp_params,grad,(rtrl_params,batch,rtrl_opt_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec(p,opt_s,random_seed):\n",
    "    random_seed,val_seed = jax.random.split(random_seed)\n",
    "    new_batch = sl.randman(manifold_key,random_seed,nb_classes=output_sz,nb_units=input_sz,nb_steps=seq_len,nb_samples=100,batch_sz=batch_sz,dim_manifold=2,alpha=2.,time_encode=True)\n",
    "    \n",
    "    p[0],opt_s[0],_,_ = bp_train(p[0],new_batch,opt_s[0])\n",
    "    p[1],opt_s[1],_,_ = ostl_train(p[1],new_batch,opt_s[1])\n",
    "    p[2],opt_s[2],_,_ = ottt_train(p[2],new_batch,opt_s[2])\n",
    "    p[3],opt_s[3],_,_ = otpe_train(p[3],new_batch,opt_s[3])\n",
    "    p[4],opt_s[4],_,_ = rtrl_train(p[4],new_batch,opt_s[4])\n",
    "\n",
    "    l = [100]*len(p)\n",
    "\n",
    "    val_batch = sl.randman(manifold_key,val_seed,nb_classes=output_sz,nb_units=input_sz,nb_steps=seq_len,nb_samples=100,batch_sz=batch_sz,dim_manifold=2,alpha=2.,time_encode=True)\n",
    "    l[0] = bp_eval(p[0],val_batch,opt_s[0])[3]\n",
    "    l[1] = jnp.mean(ostl_eval(p[1],val_batch,opt_s[1])[3])\n",
    "    l[2] = jnp.mean(ottt_eval(p[2],val_batch,opt_s[2])[3])\n",
    "    l[3] = jnp.mean(otpe_eval(p[3],val_batch,opt_s[3])[3])\n",
    "    l[4] = jnp.mean(rtrl_eval(p[4],val_batch,opt_s[4])[3])\n",
    "\n",
    "    return p,opt_s,random_seed,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tmp/bp_model_{}'.format(0),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,bp_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/ottt_model_{}'.format(0),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,ottt_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/otpe_model_{}'.format(0),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,otpe_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/rtrl_model_{}'.format(0),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,rtrl_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/ostl_model_{}'.format(0),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,ostl_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [bp_params,ostl_params,ottt_params,otpe_params,rtrl_params]\n",
    "opt_s = [bp_opt_state,ostl_opt_state,ottt_opt_state,otpe_opt_state,rtrl_opt_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bp_loss = 100\n",
    "best_ostl_loss = 100\n",
    "best_ottt_loss = 100\n",
    "best_otpe_loss = 100\n",
    "best_rtrl_loss = 100\n",
    "\n",
    "best_bp_params = bp_params\n",
    "best_ostl_params = ostl_params\n",
    "best_ottt_params = ottt_params\n",
    "best_otpe_params = otpe_params\n",
    "best_rtrl_params = rtrl_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_steps):\n",
    "    p,opt_s,random_seed,l = jax.jit(exec)(p,opt_s,random_seed)\n",
    "    if l[0] < best_bp_loss:\n",
    "        best_bp_params = p[0]\n",
    "        best_bp_loss = l[0]\n",
    "    if l[1] < best_ostl_loss:\n",
    "        best_ostl_params = p[1]\n",
    "        best_ostl_loss = l[1]\n",
    "    if l[2] < best_ottt_loss:\n",
    "        best_ottt_params = p[2]\n",
    "        best_ottt_loss = l[2]\n",
    "    if l[3] < best_otpe_loss:\n",
    "        best_otpe_params = p[3]\n",
    "        best_otpe_loss = l[3]\n",
    "    if l[4] < best_rtrl_loss:\n",
    "        best_rtrl_params = p[4]\n",
    "        best_rtrl_loss = l[4]\n",
    "\n",
    "    if (i+1) % 1_000 == 0:\n",
    "        with open('./tmp/bp_model_{}'.format((i+1)//1_000),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,p[0]),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('./tmp/ostl_model_{}'.format((i+1)//1_000),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,p[1]),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('./tmp/ottt_model_{}'.format((i+1)//1_000),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,p[2]),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('./tmp/otpe_model_{}'.format((i+1)//1_000),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,p[3]),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open('./tmp/rtrl_model_{}'.format((i+1)//1_000),'wb') as file:\n",
    "            pickle.dump(tree_map(jnp.float32,p[4]),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('./tmp/bp_model_{}'.format((5)),'wb') as file:\n",
    "    pickle.dump(tree_map(jnp.float32,best_bp_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/ostl_model_{}'.format(5),'wb') as file:\n",
    "    pickle.dump(tree_map(jnp.float32,best_ostl_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/ottt_model_{}'.format(5),'wb') as file:\n",
    "    pickle.dump(tree_map(jnp.float32,best_ottt_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/otpe_model_{}'.format(5),'wb') as file:\n",
    "    pickle.dump(tree_map(jnp.float32,best_otpe_params),file,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./tmp/rtrl_model_{}'.format(5),'wb') as file:\n",
    "    pickle.dump(tree_map(jnp.float32,best_rtrl_params),file,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = tree_structure(bp_params['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = sl.randman(manifold_key,random_seed,nb_classes=output_sz,nb_units=input_sz,nb_steps=seq_len,nb_samples=100,dim_manifold=2,alpha=2.)\n",
    "bp_test_carry = bp_model.init(key,jnp.zeros_like(test_batch[0][0]))\n",
    "bp_test_params = bp_params\n",
    "bp_test_params['carry'] = bp_test_carry['carry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(params,x):\n",
    "    s,upd = bp_model.apply(params,x,mutable='carry')\n",
    "    params.update(upd)\n",
    "    return params,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(params):\n",
    "    _,s = jax.lax.scan(apply,params,test_batch[0])\n",
    "    return jnp.mean(optax.softmax_cross_entropy(s,test_batch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(number):\n",
    "    with open('./tmp/bp_model_{}'.format(number),'rb') as file:\n",
    "        bp_params = pickle.load(file)\n",
    "    bp_params['carry'] = bp_test_carry['carry']\n",
    "    with open('./tmp/ostl_model_{}'.format(number),'rb') as file:\n",
    "        ostl_params = pickle.load(file)\n",
    "    ostl_params['params'] = tree_unflatten(struct,tree_leaves(ostl_params['params']))\n",
    "    ostl_params['carry'] = bp_test_carry['carry']\n",
    "    with open('./tmp/ottt_model_{}'.format(number),'rb') as file:\n",
    "        ottt_params = pickle.load(file)\n",
    "    ottt_params['params'] = tree_unflatten(struct,tree_leaves(ottt_params['params']))\n",
    "    ottt_params['carry'] = bp_test_carry['carry']\n",
    "    with open('./tmp/otpe_model_{}'.format(number),'rb') as file:\n",
    "        otpe_params = pickle.load(file)\n",
    "    otpe_params['params'] = tree_unflatten(struct,tree_leaves(otpe_params['params']))\n",
    "    otpe_params['carry'] = bp_test_carry['carry']\n",
    "    with open('./tmp/rtrl_model_{}'.format(number),'rb') as file:\n",
    "        rtrl_params = pickle.load(file)\n",
    "    rtrl_params['params'] = tree_unflatten(struct,tree_leaves(rtrl_params['params']))\n",
    "    rtrl_params['carry'] = bp_test_carry['carry']\n",
    "    return [ostl_params,bp_params,rtrl_params][::-1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss(load_params(3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.gen_loss_landscape(get_loss,load_params,6,2)\n",
    "plt.legend(['OSTL','BPTT','RTRL'][::-1],fontsize=25)\n",
    "plt.savefig('ll.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
